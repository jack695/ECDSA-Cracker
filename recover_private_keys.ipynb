{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utxo_utils.crypto.signature import verifySignature\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import ecdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# DATA HANDLING #\n",
    "#################\n",
    "def is_row_valid(row):\n",
    "    try:\n",
    "        verifySignature(row[\"pubkey\"], f\"{int(row[\"r\"], 16):064x}\" + f\"{int(row[\"s\"], 16):064x}\", row[\"message digest\"])\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def collect_file_paths(folders: list[str]):\n",
    "    signatures_files = []\n",
    "    for folder in folders:\n",
    "        signatures_files += glob.glob(os.path.join(folder, \"*.parquet\"))\n",
    "    return signatures_files\n",
    "\n",
    "\n",
    "def read_raw_data(signatures_folders: list[str], check_signatures: bool = False):\n",
    "    signatures_files = collect_file_paths(signatures_folders)\n",
    "    df = pd.concat(\n",
    "        pd.read_parquet(parquet_file)\n",
    "        for parquet_file in signatures_files\n",
    "    )\n",
    "\n",
    "    # Last filtering step: remove possible unvalid signatures\n",
    "    filtered_df = df if not check_signatures else df[df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\" Read the signature files and group the rows by pubkey and r such that it contains two message digests and two s.\"\"\"\n",
    "    # Group by pubkey and r. Keep two records for every row.\n",
    "    grouped_df = (\n",
    "        df[[\"pubkey\", \"r\", \"s\", \"message digest\"]]\n",
    "        .groupby(by=[\"pubkey\", \"r\"])\n",
    "        .aggregate(\n",
    "            s_cnt=(\"s\", \"nunique\"),\n",
    "            digest_cnt=(\"message digest\", \"nunique\"),\n",
    "            s=(\"s\", lambda s: s.drop_duplicates().head(2)),\n",
    "            digests=(\"message digest\", lambda s: s.drop_duplicates().head(2)),\n",
    "        )\n",
    "    )\n",
    "    # Keep the records in presence of a repeated nonce\n",
    "    grouped_df = grouped_df[(grouped_df[\"s_cnt\"] > 1) & (grouped_df[\"digest_cnt\"] > 1)]\n",
    "\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# SIG MANAGEMENT #\n",
    "##################\n",
    "def derive_private_key(\n",
    "    r: int, s1: int, s2: int, h1_str: str, h2_str: str, curve=ecdsa.SECP256k1\n",
    "):\n",
    "    # Typecasting & constants\n",
    "    order = curve.order\n",
    "    generator = curve.generator\n",
    "    h1, h2 = (\n",
    "        int(h1_str, base=16),\n",
    "        int(h2_str, base=16),\n",
    "    )\n",
    "\n",
    "    for s1, s2 in [\n",
    "        [s1, s2],\n",
    "        [order - s1, s2],\n",
    "        [s1, order - s2],\n",
    "        [order - s1, order - s2],\n",
    "    ]:\n",
    "        # Nonce derivation\n",
    "        s_diff_inv = pow((s1 - s2), -1, order)\n",
    "        nonce = ((h1 - h2) * s_diff_inv) % order\n",
    "        if r == (nonce * generator).x():\n",
    "            priv_key = pow(r, -1, order) * (s2 * nonce - h2) % order\n",
    "            sk = ecdsa.SigningKey.from_secret_exponent(\n",
    "                secexp=priv_key, curve=curve, hashfunc=None\n",
    "            )\n",
    "            vk = sk.get_verifying_key()\n",
    "            try:\n",
    "                # Check the validity of the private key, as we might have recovered -k if the user has published -s1 and -s2 (which are still valid) over the network.\n",
    "                vk.verify_digest(\n",
    "                    bytes.fromhex(f\"{r:064x}{s1:064x}\"),\n",
    "                    bytes.fromhex(h1_str),\n",
    "                )\n",
    "                vk.verify_digest(\n",
    "                    bytes.fromhex(f\"{r:064x}{s2:064x}\"),\n",
    "                    bytes.fromhex(h2_str),\n",
    "                )\n",
    "                return nonce, priv_key\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "    raise ValueError(\n",
    "        \"The nonce and the private key could not be recovered: the input signatures are probably invalid.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieve_private_keys_from_repeated_nonces(grouped_df, curve=ecdsa.SECP256k1):\n",
    "    private_keys = {}\n",
    "    nonces = {}\n",
    "    for row in grouped_df.itertuples():\n",
    "        # Data\n",
    "        pubkey = row.Index[0]\n",
    "        r = int(row.Index[1], base=16)\n",
    "        s1, s2 = map(lambda s: int(s, base=16), row.s)\n",
    "        h1, h2 = row.digests\n",
    "\n",
    "        try:\n",
    "            nonce, private_key = derive_private_key(r, s1, s2, h1, h2)\n",
    "            private_keys[pubkey] = private_key\n",
    "            if r not in nonces:\n",
    "                nonces[r] = {nonce}\n",
    "            else:\n",
    "                nonces[r].add(nonce)\n",
    "        except Exception as e:\n",
    "            print(pubkey, e)\n",
    "\n",
    "    return private_keys, nonces\n",
    "\n",
    "\n",
    "def retrieve_private_keys_from_known_nonces(\n",
    "    sigs_df, nonces_by_r: dict, private_keys: dict, curve=ecdsa.SECP256k1\n",
    "):\n",
    "    # Fetch the rows for which we know the nonce to generate the 'r' value and for those the private key has not been recovered\n",
    "    df = sigs_df[\n",
    "        sigs_df.apply(\n",
    "            lambda row: int(row[\"r\"], 16) in nonces_by_r\n",
    "            and row[\"pubkey\"] not in private_keys,\n",
    "            axis=1,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Group those records by public key and 'r'\n",
    "    df = df.groupby(by=[\"pubkey\", \"r\"]).aggregate(\n",
    "        s=(\"s\", lambda s: s.drop_duplicates().head(1)),\n",
    "        digest=(\"message digest\", lambda s: s.drop_duplicates().head(1)),\n",
    "    )\n",
    "\n",
    "    private_keys = {}\n",
    "    order = curve.order\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        # Data\n",
    "        pubkey = row.Index[0]\n",
    "        r = int(row.Index[1], base=16)\n",
    "        s = int(row.s, 16)\n",
    "        h_str = row.digest\n",
    "        h = int(h_str, 16)\n",
    "\n",
    "        nonces = list(nonces_by_r[r])\n",
    "        expected_vk = ecdsa.VerifyingKey.from_string(bytes.fromhex(pubkey), curve=curve)\n",
    "        # We have to be careful that for a given nonce and given signature, 2 private keys are valid, see ecdsa_tutorial (mirror_key)\n",
    "        for nonce in nonces:\n",
    "            priv_key = pow(r, -1, order) * (s * nonce - h) % order\n",
    "            sk = ecdsa.SigningKey.from_secret_exponent(\n",
    "                secexp=priv_key, curve=curve, hashfunc=None\n",
    "            )\n",
    "            vk = sk.get_verifying_key()\n",
    "\n",
    "            if vk != expected_vk:\n",
    "                # Let's fetch the alternative private key, that could have signed that message\n",
    "                priv_key = (pow(r, -1, order) * s * (-2 * nonce) + priv_key) % order\n",
    "                sk = ecdsa.SigningKey.from_secret_exponent(\n",
    "                    secexp=priv_key, curve=curve, hashfunc=None\n",
    "                )\n",
    "                vk = sk.get_verifying_key()\n",
    "\n",
    "            assert vk == expected_vk\n",
    "            private_keys[pubkey] = priv_key\n",
    "\n",
    "    return private_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# POST CHECKING #\n",
    "#################\n",
    "def verify_private_keys(privkeys_by_pubkey: dict, curve=ecdsa.SECP256k1):\n",
    "    # Verify that every recovered private key is valid\n",
    "    for pubkey, privkey in privkeys_by_pubkey.items():\n",
    "\n",
    "        vk_expected = ecdsa.VerifyingKey.from_string(bytes.fromhex(pubkey), curve=curve)\n",
    "        sk = ecdsa.SigningKey.from_secret_exponent(secexp=privkey, curve=curve)\n",
    "        vk = sk.get_verifying_key()\n",
    "\n",
    "        assert vk == vk_expected\n",
    "\n",
    "\n",
    "def verify_nonces(nonces_by_r: dict, curve=ecdsa.SECP256k1):\n",
    "    for r, nonces in nonces_by_r.items():\n",
    "        # As every x coor. is shared by two points, two nonces can generate two points with the same x coor., i.e. the same 'r'.\n",
    "        assert len(nonces) > 0 and len(nonces) <= 2\n",
    "        for nonce in nonces:\n",
    "            assert (curve.generator * nonce).x() == r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385 private keys found from a set of 1385 public keys associated with repeated nonces.\n",
      "1260 private keys found from a set of 21760 public keys associated with nonces being used multiple times by other users.\n",
      "2645 private keys found in total.\n"
     ]
    }
   ],
   "source": [
    "bch_signatures_folders = [\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/bch\",\n",
    "]\n",
    "\n",
    "signatures_folders = [\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/btc\",\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/dash\",\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/bch\",\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/ltc\",\n",
    "    \"/Users/vincent/Documents/PhD/Blockchains/UTXO/ecdsa-signatures/local/signatures/doge\",\n",
    "]\n",
    "\n",
    "# Retrieve the private keys\n",
    "\n",
    "bch_sig_df = read_raw_data(bch_signatures_folders, check_signatures=True)\n",
    "other_sig_df = read_raw_data(signatures_folders, check_signatures=False)\n",
    "sig_df = pd.concat([bch_sig_df, other_sig_df])\n",
    "df = prepare_data(sig_df)\n",
    "private_keys, nonces_by_r = retrieve_private_keys_from_repeated_nonces(df)\n",
    "\n",
    "# Check the validity of the results\n",
    "verify_private_keys(private_keys)\n",
    "verify_nonces(nonces_by_r)\n",
    "\n",
    "# Now, from the set of known (r, nonce) pairs, derive private keys from signatures that used those nonce even once\n",
    "extra_private_keys = retrieve_private_keys_from_known_nonces(sig_df, nonces_by_r, private_keys)\n",
    "\n",
    "# Check those keys as well\n",
    "verify_private_keys(extra_private_keys)\n",
    "\n",
    "# Print some stats\n",
    "print(f\"{len(private_keys)} private keys found from a set of {df.reset_index()[\"pubkey\"].nunique()} public keys associated with repeated nonces.\")\n",
    "print(f\"{len(extra_private_keys)} private keys found from a set of {sig_df.reset_index()[\"pubkey\"].nunique()} public keys associated with nonces being used multiple times by other users.\")\n",
    "print(f\"{len(private_keys | extra_private_keys)} private keys found in total.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
